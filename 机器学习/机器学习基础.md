
## 机器学习基础问题


### 数据（类别）不平衡解决办法

**类别不平衡（class-imbalance）** 指在分类任务中不同类别的训练样例数目差别很大的情况。

假设正类样例的数量少，负类样例的数量多。

**1. 再缩放（再平衡）**
	$$\frac{y'}{1-y'}=\frac{y}{1-y}\times \frac{m^-}{m^+}\tag{1}$$
	其中$y$表示分类器输出的的结果，即正类的概率。
**2. 欠采样（undersampling）**
	删除一些负类样例，使得正负样例数目接近，然后再学习。
**3. 过采样（oversampling）**
    增加一些正例使得正负样例数目接近，再进行学习。
**4. 阈值移动（threshold-moving）**
    直接基于原始训练集进行学习，在预测时将公式(1)嵌入决策过程中。
**5. 采用集成算法（bagging/boosting）**

参考：周志华《机器学习》

### 数据归一化和标准化